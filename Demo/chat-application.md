## Build a chat application with Open Web UI
This tutorial shows you how to create a chat application using Foundry Local and Open Web UI. When you finish, you'll have a working chat interface running entirely on your local device.

## Prerequisites
Before you start this tutorial, you need:

Foundry Local installed on your computer.
At least one model loaded with the foundry model load command, like this:
foundry model load Phi-4-mini-instruct-cuda-gpu
Set up Open Web UI for chat
Install Open Web UI by following the instructions from the Open Web UI GitHub repository.

Launch Open Web UI with this command in your terminal:

open-webui serve
Open your web browser and go to http://localhost:8080.

Connect Open Web UI to Foundry Local:

Select Settings in the navigation menu
Select Connections
Select Manage Direct Connections
Select the + icon to add a connection
Enter http://localhost:PORT/v1 for the URL, where PORT is the port number assigned to your Foundry Local instance.
Type any value (like test) for the API Key, since it cannot be empty
Save your connection
image

Start chatting with your model:
Your loaded models will appear in the dropdown at the top
Select any model from the list
Type your message in the input box at the bottom
That's it! You're now chatting with an AI model running entirely on your local device.

